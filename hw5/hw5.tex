\documentclass{article}
\linespread{1.3}
\usepackage[margin=50pt]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsthm, tikz, fancyhdr, graphicx}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\newcommand{\changefont}{\fontsize{15}{15}\selectfont}

\fancypagestyle{firstpageheader}
{
  \fancyhead[R]{\changefont Michael Huang \\ CFRM 420 \\ Homework 4}
}

\begin{document}

\thispagestyle{firstpageheader}

\section*{1.}
{\Large 

Let $\{Z_t\} \sim \text{GWN}(0, 1).$ Let $Y_t = Z_tZ_{t-1}, t \in \mathbb{Z} $

% \begin{verbatim}
%   Text enclosed inside \texttt{verbatim}
%   environment 
%   is printed directly 
%   and all \LaTeX{} commands are ignored.
% \end{verbatim}

% \framebox[1.1\width]{\textbf{answer}}

\subsection*{(a)}

We know that by definition, $Z \sim \text{WN}(0, 1)$, that is, $Z \sim \text{IID}(0, 1)$ and $Z_t \sim \text{N}(0, 1)$. 
To show that $\{Y_t\}_{t \in \mathbb{Z}}$ is white noise, we need to prove the following conditions: \\ \\ 
$\mathbb{E}[Y_t] = 0$. We know that the expectation of two IID variables is their product, so we can show that \\
$\mathbb{E}[Y_t] \\ = \mathbb{E}[Z_tZ_{t-1}] \\ = \mathbb{E}[Z_t] \cdot \mathbb{E}[Z_{t-1}] \\ = 0 \cdot 0 = 0$ \hfill since $Z$ is Gaussian white noise. \\ \\ 
$\text{Var}(Y_t) = \sigma^2 = 1$. We can calculate this by definition as well: \\
$\text{Var}(Y_t)$ \\
$= \text{Var}(Z_tZ_{t-1})$ \\ 
$= \mathbb{E}(Z_{t-1})^2\text{Var}(Z_t) + \text{Var}(Z_{t-1})\mathbb{E}[Z_t^2]$ \\
$= 0^2 \cdot 1 + 1 \cdot \text{Var}(Z_t) + [\mathbb{E}(Z_t)]^2$ \hfill by definition of $\mathbb{E}[X^2]$ \\
$= 0 + 1 \cdot  1 + 0^2$ \\
$= 1$ \\ \\
$\text{Corr}(Y_k, Y_l) = 0$ for all $k \neq l$. We know by definition that \\
$\text{Corr}(Y_k, Y_l)$ \\ 
$= \frac{\text{Cov}(Y_k, Y_l)}{\sqrt{Var(Y_k)Var(Y_l)}}$ \\
$= \frac{\text{Cov}(Z_kZ_{k-1}, Z_lZ_{l-1})}{\sqrt{Var(Z_kZ_{k-1})Var(Z_kZ_{k-1})}} $ \\ 
$= \frac{\text{Cov}(Z_kZ_{k-1}, Z_lZ_{l-1})}{\sqrt{1 \cdot 1}} $ \hfill as we previously showed \\ 
$= \frac{\mathbb{E}[Z_kZ_{k-1}Z_lZ_{l-1}] - \mathbb{E}[Z_kZ_{k-1}]\mathbb{E}[Z_lZ_{l-1}]}{\sqrt{1}} $ \hfill by definition of covariance \\ 
$= \frac{0 \cdot 0 \cdot 0 \cdot 0 - (0 \cdot 0) \cdot (0 \cdot 0)}{\sqrt{1 \cdot 1}
} $ \hfill as we previously showed and by definition \\
$= \frac{0}{1} = 0.$ \\ \\ 
In proving all these conditions, we have shown that $\{Y_t\}_{t \in \mathbb{Z}}$ is white noise.

\subsection*{(b)}

If $\{Y_t\}_{t \in \mathbb{Z}}$ were an IID sequence, we could calculate this using definition of expectation:
$\mathbb{E}[Y_t^2Y_{t-1}^2]$ \\ 
$= (\text{Var}(Y_t) + \mathbb{E}[Y_t]^2) \cdot (\text{Var}(Y_{t-1}) + \mathbb{E}[Z_{t-1}]^2)$ \\
$= (1 + 0^2) \cdot (1 + 0^2)$ \hfill by definition of $Y_t, Y_{t-1}$ \\ 
= 1. \\ \\ 
However, we can see that \\
$\mathbb{E}[Y_t^2Y_{t-1}^2]$ \\
$= \mathbb{E}[Z_t^2Z_{t-1}^2Z_{t-1}^2Z_{t-2}^2]$ \\
$= \mathbb{E}[Z_t^2Z_{t-1}^4Z_{t-2}^2]$ \\
At this point, we see the common underlying $Z_{t-1}$ term, which indicates that this is not IID.  We can go further using moments and chi-squared to go further mathematically: \\ 
$= \mathbb{E}[1 \cdot Z_{t-1}^4 \cdot 1]$ \hfill as we previously calculated \\
$= \mathbb{E}[Z_{t-1}^4]$ \\ 
% check this later
$= 3 * 1 = 3$ \hfill by definition \\ 
which we can clearly see does not equate. 

\newpage

\subsection*{(c)}

We plot this in R: 
\begin{figure}[h!]
  \centering
  \includegraphics[width=500pt]{hw4_1c.png}
\end{figure}

\newpage

}

\section*{2.}
{\Large

Consider the process $Y_t = \phi Y_{t-1} + \varepsilon_t$ with $t = 1, 2, \dots$ \\
where 

\subsection*{(a)}

Since $\varepsilon_t \sim \text{WN}(0,1)$, we know that it has $\mathbb{E}[\varepsilon_t] = 0$ by definition. This therefore doesn't contribute to any $\mathbb{E}[Y_t]$, so we can just take this out and only consider the $\phi Y_{t-1}$ term. For $t = 0$, we can use the initial value definition to see that $Y_1 = \phi \mathbb{E}[Y_0] = \phi \cdot 0 = 0$. It therefore follows for any of the following terms that $\mathbb{Y_t} = 0$, as $\mathbb{E}[Y_t] = \phi \cdot \mathbb{E}[Y_{t-1}] + \mathbb{E}(\varepsilon_t) = \phi \cdot 0 + 0 = 0 + 0 = 0$.

\subsection*{(b)}

We know by definition that $Y_t = \phi Y_{t-1} + \varepsilon_t$, or equivalently \\
$Y_{t+1} = \phi Y_t + \varepsilon_{t+1}$ \\
$Y_{t+2} = \phi^2 Y_{t+1} + \phi\varepsilon_{t+1} + \varepsilon_{t+2}$ \\ 
$Y_{t+3} = \phi^3 Y_{t+2} + \phi^2\varepsilon_{t+1} + \phi\varepsilon_{t+2} + \varepsilon_{t+3}$ \\ 
etc. Equivalently, we can say that \\ $Y_{t+h} = \phi^h Y_{t} + \sum_{i=0}^{h-1} \phi^i\varepsilon_{t+h-i}$ \\ \\
% ?????
We can now show that \\
$\text{Cov}(Y_t, Y_{t+h})$ \\
$ = \text{Cov}(\phi Y_{t-1} + \varepsilon_t, Y_{t+h})$ \\
$ = \text{Cov}(\phi Y_{t-1} + \varepsilon_t, \phi^h Y_{t} + \sum_{i=0}^{h-1} \phi^i\varepsilon_{t+h-i})$ \\
$ = \phi^{h+1}\text{Cov}(Y_{t-1}, Y_{t}) + \text{Cov}(\varepsilon_t, Y_{t}) + \text{Cov}(Y_{t-1}, \sum_{i=0}^{h-1} \phi^i\varepsilon_{t+h-i}) + \text{Cov}(\varepsilon_t, \sum_{i=0}^{h-1} \phi^i\varepsilon_{t+h-i})$ \\
$ = \phi^{h+1}\text{Cov}(Y_{t-1}, Y_{t}) + 0 + 0 + 0$ \hfill by definitions of $\varepsilon, Y_t$ \\ 
$= \phi^{h+1} \gamma(1)$ \\
$= \phi^{h+1} \frac{\sigma^2}{1-\phi^2}\phi^1 = \phi^{h+1} \frac{\sigma^2}{1-\phi^2}$ \\ 
which clearly does not depend on $t$.

\subsection*{(c)}

We plot this in R: 
\begin{figure}[h!]
  \centering
  \includegraphics[width=500pt]{hw4_2c.png}
\end{figure}

\subsection*{(d)}

We have an initial value given to us at 0, so we don't need to simulate the values from an infinite period of previous times, so we don't need to calculate this in the manner of a series that started infinitely backwards in time, so we don't need to worry about burn-in in this case.
% We don't fix the initial value, so we dont need to worry about burn-in and discard the first batch of simulated values. The process is covariance stationary from the start. 

\newpage

\subsection*{(e)}

This line essentially just keeps going upwards exponentially. (monotonically increasing).
\begin{figure}[h]
  \centering
  \includegraphics[width=500pt]{hw4_2e.png}
\end{figure}

}

\end{document}